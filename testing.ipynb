{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import ale_py\n",
    "# pip install ale-py\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import pickle\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import namedtuple, deque\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "gym.register_envs(ale_py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Memory():\n",
    "    def __init__(self, capacity, file=None):\n",
    "        if file is not None:\n",
    "            try:\n",
    "                with open(file, \"rb\") as f:\n",
    "                    d = pickle.load(f)\n",
    "                    self.memory = d\n",
    "            except Exception as e:\n",
    "                self.memory = deque([], maxlen=capacity)\n",
    "                print(e)\n",
    "        else:\n",
    "            self.memory = deque([], maxlen=capacity)\n",
    "\n",
    "    def push(self, el):\n",
    "        self.memory.append(el)\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)\n",
    "\n",
    "    def to_list(self):\n",
    "        return list(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, channels, kernel, pool_kernel):\n",
    "        super(DoubleConv, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(channels[0], channels[1], kernel)\n",
    "        self.conv2 = nn.Conv2d(channels[1], channels[2], kernel)\n",
    "        self.pool_kernel = pool_kernel\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, self.pool_kernel)\n",
    "        return x\n",
    "\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DQN, self).__init__()\n",
    "        self.double_conv1 = DoubleConv(channels=(3, 4, 8), kernel=(5,5), pool_kernel=(2,2))\n",
    "        self.double_conv2 = DoubleConv(channels=(8, 8, 16), kernel=(5,5), pool_kernel=(3,3))\n",
    "\n",
    "\n",
    "\n",
    "        self.layer1 = nn.Linear(145, 256)\n",
    "        self.layer2 = nn.Linear(256, 256)\n",
    "        self.layer3 = nn.Linear(256, 3)        \n",
    "\n",
    "    def forward(self, x, f):\n",
    "        x = F.max_pool2d(x, (3,3))\n",
    "        x = self.double_conv1(x)\n",
    "        x = self.double_conv2(x)\n",
    "        x = torch.flatten(x, x.dim()-3)\n",
    "        x = torch.cat((x, f), x.dim()-1)\n",
    "        x = F.relu(self.layer1(x))\n",
    "        x = F.relu(self.layer2(x))\n",
    "        return self.layer3(x)\n",
    "\n",
    "\n",
    "def optimize_model(optimizer, memory, policy_net, target_net):\n",
    "    if len(memory) < BATCH_SIZE:\n",
    "        return\n",
    "    transitions = memory.sample(BATCH_SIZE)\n",
    "    state_batch = torch.tensor(np.array([state for (state, _, _, _, _, _) in transitions]), dtype=torch.float32)\n",
    "    feature_batch = torch.tensor(np.array([f for (_, f, _, _, _, _) in transitions]), dtype=torch.float32)\n",
    "\n",
    "    action_batch = torch.tensor([[action] for (_, _, action, _, _, _) in transitions])\n",
    "    reward_batch =  torch.tensor([reward for (_, _, _, reward, _, _) in transitions])\n",
    "    next_state_batch = torch.tensor(np.array([s2 for (_, _, _, _, s2, _) in transitions]), dtype=torch.float32)\n",
    "    next_feature_batch = torch.tensor(np.array([f for (_, _, _, _, _, f) in transitions]), dtype=torch.float32)\n",
    "\n",
    "\n",
    "\n",
    "    state_qvalues = policy_net(state_batch, feature_batch)\n",
    "    state_action_values = state_qvalues.squeeze(1).gather(1, action_batch).squeeze(1)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        next_qvalues = target_net(next_state_batch, next_feature_batch).squeeze(1)\n",
    "        next_state_values = next_qvalues.max(axis=1).values\n",
    "        next_state_values = torch.tensor(next_state_values)\n",
    "    expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n",
    "\n",
    "    criterion = nn.SmoothL1Loss()\n",
    "\n",
    "    loss = criterion(state_action_values, expected_state_action_values)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_value_(policy_net.parameters(), 100)\n",
    "    optimizer.step()\n",
    "\n",
    "    target_net_state_dict = target_net.state_dict()\n",
    "    policy_net_state_dict = policy_net.state_dict()\n",
    "    for key in policy_net_state_dict:\n",
    "        target_net_state_dict[key] = policy_net_state_dict[key]*TAU + target_net_state_dict[key]*(1-TAU)\n",
    "    target_net.load_state_dict(target_net_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncate_picture(observation):\n",
    "    return observation[40:180, 10:-10, :]\n",
    "\n",
    "def find_pole_middle(observation):\n",
    "    for i in range(observation.shape[0]):\n",
    "        where = (observation[i, :, 0] < 100) & (observation[i, :, 1] < 100)\n",
    "        blue_pixels = sum(where)\n",
    "        if blue_pixels == 10:\n",
    "            return sum(np.where(where)[0])/10\n",
    "    return None\n",
    "\n",
    "def find_player_pos(observation):\n",
    "    for i in range(observation.shape[0]):\n",
    "        where = (observation[i, :, 1] < 100) & (observation[i, :, 2] < 100)\n",
    "        red_pixels = sum(where)\n",
    "        if red_pixels > 0:\n",
    "            return sum(np.where(where)[0])/red_pixels\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_extra_features(observation):\n",
    "    pole = find_pole_middle(observation)\n",
    "    player = find_player_pos(observation)\n",
    "    delta = (pole-player)/observation.shape[1]\n",
    "    return [delta]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_game(optimizer, memory, policy_net, target_net, MAX_ITER=1000):\n",
    "    env = gym.make('ALE/Skiing-v5')\n",
    "    obs, info = env.reset()\n",
    "    obs = truncate_picture(obs)\n",
    "    last_features = extract_extra_features(obs)\n",
    "    obs = np.swapaxes(np.swapaxes(obs, 1, 2), 0, 1)\n",
    "    done = False\n",
    "    game_start = time.time()\n",
    "    action_sum, action_cnt = 0, 0\n",
    "    while not done and action_cnt < MAX_ITER:\n",
    "        s = time.time()\n",
    "        optimize_model(optimizer, memory, policy_net, target_net)\n",
    "        if random.random() < EPSILON:\n",
    "            res = target_net(torch.tensor(obs, dtype=torch.float32), torch.tensor(last_features, dtype=torch.float32)).detach().numpy()\n",
    "            action = np.argmax(res)\n",
    "        else:\n",
    "            action = int(random.random()*A)\n",
    "        diff = time.time()-s\n",
    "        action_sum += (diff)\n",
    "        print(diff)\n",
    "        action_cnt += 1\n",
    "        for _ in range(ACTION_REPETITION):\n",
    "            observation, reward, done, trunc, info = env.step(action)\n",
    "            if done:\n",
    "                break\n",
    "        observation = truncate_picture(observation)\n",
    "        features = extract_extra_features(observation)\n",
    "        observation = np.swapaxes(np.swapaxes(observation, 1, 2), 0, 1)\n",
    "        memory.push((obs, last_features, action, reward, observation, features))\n",
    "        obs = observation\n",
    "        last_features = features\n",
    "\n",
    "    print(f\"Game done in {time.time()-game_start}s, avg it length {action_sum/action_cnt}\")\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: './memory'\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 128\n",
    "GAMMA = 0.95\n",
    "TAU = 0.005\n",
    "LR = 0.0005\n",
    "EPSILON = 0.8\n",
    "A = 3\n",
    "MODEL_PATH = \"./\"\n",
    "MEMORY_PATH = \"./memory\"\n",
    "ACTION_REPETITION = 5\n",
    "\n",
    "\n",
    "target_net = DQN()\n",
    "target_net.load_state_dict(torch.load(MODEL_PATH+\"target\", weights_only=True, map_location=torch.device('cpu')))\n",
    "policy_net = DQN()\n",
    "policy_net.load_state_dict(target_net.state_dict())\n",
    "policy_net.load_state_dict(torch.load(MODEL_PATH+\"policy\", weights_only=True, map_location=torch.device('cpu')))\n",
    "\n",
    "\n",
    "\n",
    "memory = Memory(10**5, file=MEMORY_PATH)\n",
    "optimizer = optim.AdamW(policy_net.parameters(), lr=LR, amsgrad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12933349609375\n",
      "6.4373016357421875e-06\n",
      "0.12173986434936523\n",
      "0.12244367599487305\n",
      "0.17440509796142578\n",
      "4.76837158203125e-06\n",
      "3.0994415283203125e-06\n",
      "0.14007806777954102\n",
      "0.11710548400878906\n",
      "0.2473914623260498\n",
      "0.1936025619506836\n",
      "0.25324392318725586\n",
      "0.1252305507659912\n",
      "6.198883056640625e-06\n",
      "0.19405889511108398\n",
      "4.291534423828125e-06\n",
      "0.10889697074890137\n",
      "0.0866086483001709\n",
      "0.09357810020446777\n",
      "0.15236186981201172\n",
      "0.14271330833435059\n",
      "0.06708812713623047\n",
      "5.9604644775390625e-06\n",
      "0.10938215255737305\n",
      "0.1006004810333252\n",
      "3.337860107421875e-06\n",
      "0.11878490447998047\n",
      "0.15051960945129395\n",
      "0.0654909610748291\n",
      "0.048821449279785156\n",
      "0.07859659194946289\n",
      "0.1241908073425293\n",
      "0.07184243202209473\n",
      "5.0067901611328125e-06\n",
      "0.061943769454956055\n",
      "0.07558202743530273\n",
      "0.12419462203979492\n",
      "0.06403923034667969\n",
      "0.08605694770812988\n",
      "5.0067901611328125e-06\n",
      "0.0895698070526123\n",
      "0.0377199649810791\n",
      "0.03713202476501465\n",
      "5.0067901611328125e-06\n",
      "1.9073486328125e-06\n",
      "0.07907319068908691\n",
      "0.1792464256286621\n",
      "4.0531158447265625e-06\n",
      "0.1956160068511963\n",
      "3.814697265625e-06\n",
      "2.6226043701171875e-06\n",
      "0.15099859237670898\n",
      "0.20819973945617676\n",
      "0.0662989616394043\n",
      "0.21452713012695312\n",
      "0.11859822273254395\n",
      "0.0736844539642334\n",
      "0.14026474952697754\n",
      "0.07414650917053223\n",
      "0.14104437828063965\n",
      "0.10691261291503906\n",
      "0.08587217330932617\n",
      "0.07704830169677734\n",
      "5.0067901611328125e-06\n",
      "0.062094688415527344\n",
      "0.13208365440368652\n",
      "0.08799433708190918\n",
      "0.12376165390014648\n",
      "3.5762786865234375e-06\n",
      "0.031119108200073242\n",
      "0.02200603485107422\n",
      "5.7220458984375e-06\n",
      "0.05387234687805176\n",
      "0.0625760555267334\n",
      "0.06476879119873047\n",
      "0.16960954666137695\n",
      "0.11185526847839355\n",
      "0.06741857528686523\n",
      "0.11195588111877441\n",
      "4.0531158447265625e-06\n",
      "0.14460372924804688\n",
      "0.09935879707336426\n",
      "0.09932637214660645\n",
      "5.245208740234375e-06\n",
      "0.09320902824401855\n",
      "6.198883056640625e-06\n",
      "0.09021735191345215\n",
      "0.10980725288391113\n",
      "0.1300342082977295\n",
      "0.11739349365234375\n",
      "0.09831666946411133\n",
      "0.1322643756866455\n",
      "0.07229781150817871\n",
      "4.5299530029296875e-06\n",
      "0.11270546913146973\n",
      "0.20230627059936523\n",
      "0.10082435607910156\n",
      "4.291534423828125e-06\n",
      "0.04520440101623535\n",
      "0.07110476493835449\n",
      "0.06515312194824219\n",
      "0.13225769996643066\n",
      "0.12285542488098145\n",
      "4.291534423828125e-06\n",
      "0.09254980087280273\n",
      "0.07076454162597656\n",
      "5.245208740234375e-06\n",
      "4.291534423828125e-06\n",
      "0.11626887321472168\n",
      "0.06503653526306152\n",
      "3.814697265625e-06\n",
      "3.5762786865234375e-06\n",
      "2.1457672119140625e-06\n",
      "0.1122140884399414\n",
      "0.10602450370788574\n",
      "0.06112217903137207\n",
      "0.07177877426147461\n",
      "0.08779525756835938\n",
      "0.09852433204650879\n",
      "0.0631568431854248\n",
      "4.76837158203125e-06\n",
      "0.07002830505371094\n",
      "0.15823698043823242\n",
      "0.12044310569763184\n",
      "0.04074692726135254\n",
      "0.06792497634887695\n",
      "0.07875823974609375\n",
      "0.06138110160827637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_60264/238133754.py:57: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  next_state_values = torch.tensor(next_state_values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.86844801902771\n",
      "1.2687337398529053\n",
      "2.233883857727051\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[92], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m----> 2\u001b[0m     play_game(optimizer, memory, policy_net, target_net)\n",
      "Cell \u001b[0;32mIn[91], line 12\u001b[0m, in \u001b[0;36mplay_game\u001b[0;34m(optimizer, memory, policy_net, target_net, MAX_ITER)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m done \u001b[38;5;129;01mand\u001b[39;00m action_cnt \u001b[38;5;241m<\u001b[39m MAX_ITER:\n\u001b[1;32m     11\u001b[0m     s \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 12\u001b[0m     optimize_model(optimizer, memory, policy_net, target_net)\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m random\u001b[38;5;241m.\u001b[39mrandom() \u001b[38;5;241m<\u001b[39m EPSILON:\n\u001b[1;32m     14\u001b[0m         res \u001b[38;5;241m=\u001b[39m target_net(torch\u001b[38;5;241m.\u001b[39mtensor(obs, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32), torch\u001b[38;5;241m.\u001b[39mtensor(last_features, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32))\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "Cell \u001b[0;32mIn[83], line 65\u001b[0m, in \u001b[0;36moptimize_model\u001b[0;34m(optimizer, memory, policy_net, target_net)\u001b[0m\n\u001b[1;32m     62\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(state_action_values, expected_state_action_values)\n\u001b[1;32m     64\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 65\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     66\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_value_(policy_net\u001b[38;5;241m.\u001b[39mparameters(), \u001b[38;5;241m100\u001b[39m)\n\u001b[1;32m     67\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/_tensor.py:521\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    513\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    514\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    519\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    520\u001b[0m     )\n\u001b[0;32m--> 521\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[1;32m    522\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[1;32m    523\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/autograd/__init__.py:289\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    284\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    286\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 289\u001b[0m _engine_run_backward(\n\u001b[1;32m    290\u001b[0m     tensors,\n\u001b[1;32m    291\u001b[0m     grad_tensors_,\n\u001b[1;32m    292\u001b[0m     retain_graph,\n\u001b[1;32m    293\u001b[0m     create_graph,\n\u001b[1;32m    294\u001b[0m     inputs,\n\u001b[1;32m    295\u001b[0m     allow_unreachable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    296\u001b[0m     accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    297\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/autograd/graph.py:769\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    767\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    768\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 769\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    770\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    771\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    772\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    773\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    play_game(optimizer, memory, policy_net, target_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = \"./\"\n",
    "torch.save(target_net.state_dict(), MODEL_PATH+\"target\")\n",
    "torch.save(policy_net.state_dict(), MODEL_PATH+\"policy\")\n",
    "with open(MEMORY_PATH, 'wb') as f:\n",
    "    pickle.dump(memory.memory, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109875\n"
     ]
    }
   ],
   "source": [
    "model_parameters = filter(lambda p: p.requires_grad, policy_net.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(140, 140, 3)\n",
      "Pole: 50.0\n",
      "Player: 64.5\n",
      "Pole: 50.0\n",
      "Player: 57.5\n",
      "Pole: 50.0\n",
      "Player: 51.5\n",
      "Pole: 80.0\n",
      "Player: 52.5\n",
      "Pole: 80.0\n",
      "Player: 61.5\n",
      "Pole: 80.0\n",
      "Player: 71.5\n",
      "Pole: 80.0\n",
      "Player: 82.5\n",
      "Pole: 88.0\n",
      "Player: 96.5\n",
      "Pole: 88.0\n",
      "Player: 107.5\n",
      "Pole: 88.0\n",
      "Player: 117.5\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env = gym.make('ALE/Skiing-v5')\n",
    "env.reset()\n",
    "observation, reward, done, trunc, info = env.step(0)\n",
    "truncated_obs = observation[40:180, 10:-10, :]\n",
    "print(truncated_obs.shape)\n",
    "\n",
    "for i in range(10):\n",
    "    for j in range(10):\n",
    "        observation, reward, done, trunc, info = env.step(int(random.random()*3))\n",
    "    truncated_obs = truncate_picture(observation)\n",
    "    print(f\"Pole: {find_pole_middle(truncated_obs)}\")\n",
    "    print(f\"Player: {find_player_pos(truncated_obs)}\")\n",
    "plt.imshow(truncated_obs, interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
