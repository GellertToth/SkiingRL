{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import ale_py\n",
    "# pip install ale-py\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import pickle\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import namedtuple, deque\n",
    "import time\n",
    "gym.register_envs(ale_py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Memory():\n",
    "    def __init__(self, capacity, file=None):\n",
    "        if file is not None:\n",
    "            try:\n",
    "                with open(file, \"rb\") as f:\n",
    "                    d = pickle.load(f)\n",
    "                    self.memory = d\n",
    "            except Exception as e:\n",
    "                self.memory = deque([], maxlen=capacity)\n",
    "                print(e)\n",
    "        else:\n",
    "            self.memory = deque([], maxlen=capacity)\n",
    "\n",
    "    def push(self, el):\n",
    "        self.memory.append(el)\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)\n",
    "\n",
    "    def to_list(self):\n",
    "        return list(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, channels, kernel):\n",
    "        super(DoubleConv, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(channels[0], channels[1], kernel)\n",
    "        self.conv2 = nn.Conv2d(channels[1], channels[2], kernel)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, (2,2))\n",
    "        return x\n",
    "\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DQN, self).__init__()\n",
    "        self.double_conv1 = DoubleConv(channels=(3, 4, 8), kernel=(5,5))\n",
    "        self.double_conv2 = DoubleConv(channels=(8, 8, 16), kernel=(5,5))\n",
    "        self.double_conv3 = DoubleConv(channels=(16, 16, 32), kernel=(5,5))\n",
    "\n",
    "        self.layer1 = nn.Linear(7904, 1024)\n",
    "        self.layer2 = nn.Linear(1024, 512)\n",
    "        self.layer3 = nn.Linear(512, 3)        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.double_conv1(x)\n",
    "        x = self.double_conv2(x)\n",
    "        x = self.double_conv3(x)\n",
    "        x = torch.flatten(x, x.dim()-3)\n",
    "        x = F.relu(self.layer1(x))\n",
    "        x = F.relu(self.layer2(x))\n",
    "        return self.layer3(x)\n",
    "\n",
    "\n",
    "def optimize_model(optimizer, memory, policy_net, target_net):\n",
    "    if len(memory) < BATCH_SIZE:\n",
    "        return\n",
    "    transitions = memory.sample(BATCH_SIZE)\n",
    "    state_batch = torch.tensor(np.array([state for (state, _, _, _) in transitions]), dtype=torch.float32)\n",
    "    action_batch = torch.tensor([[action] for (_, action, _, _,) in transitions])\n",
    "    reward_batch =  torch.tensor([reward for (_, _, reward, _) in transitions])\n",
    "    next_state_batch = torch.tensor(np.array([s2 for (_, _, _, s2) in transitions]), dtype=torch.float32)\n",
    "\n",
    "\n",
    "    state_qvalues = policy_net(state_batch)\n",
    "    state_action_values = state_qvalues.squeeze(1).gather(1, action_batch).squeeze(1)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        next_qvalues = target_net(next_state_batch).squeeze(1)\n",
    "        next_state_values = next_qvalues.max(axis=1).values\n",
    "        next_state_values = torch.tensor(next_state_values)\n",
    "    expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n",
    "\n",
    "    criterion = nn.SmoothL1Loss()\n",
    "\n",
    "    loss = criterion(state_action_values, expected_state_action_values)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_value_(policy_net.parameters(), 100)\n",
    "    optimizer.step()\n",
    "\n",
    "    target_net_state_dict = target_net.state_dict()\n",
    "    policy_net_state_dict = policy_net.state_dict()\n",
    "    for key in policy_net_state_dict:\n",
    "        target_net_state_dict[key] = policy_net_state_dict[key]*TAU + target_net_state_dict[key]*(1-TAU)\n",
    "    target_net.load_state_dict(target_net_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_game(optimizer, memory, policy_net, target_net, MAX_ITER=1000):\n",
    "    env = gym.make('ALE/Skiing-v5')\n",
    "    obs, info = env.reset()\n",
    "    obs = np.swapaxes(np.swapaxes(obs, 1, 2), 0, 1)\n",
    "    done = False\n",
    "    game_start = time.time()\n",
    "    action_sum, action_cnt = 0, 0\n",
    "    while not done and action_cnt < MAX_ITER:\n",
    "        s = time.time()\n",
    "        optimize_model(optimizer, memory, policy_net, target_net)\n",
    "        if random.random() < EPSILON:\n",
    "            res = target_net(torch.tensor(obs, dtype=torch.float32)).detach().numpy()\n",
    "            action = np.argmax(res)\n",
    "        else:\n",
    "            action = int(random.random()*A)\n",
    "        action_sum += (time.time()-s)\n",
    "        action_cnt += 1\n",
    "        observation, reward, done, trunc, info = env.step(action)\n",
    "        observation = np.swapaxes(np.swapaxes(observation, 1, 2), 0, 1)\n",
    "        memory.push((obs, action, reward, observation))\n",
    "        obs = observation\n",
    "\n",
    "    print(f\"Game done in {time.time()-game_start}s, avg it length {action_sum/action_cnt}\")\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: './memory'\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 128\n",
    "GAMMA = 0.95\n",
    "TAU = 0.005\n",
    "LR = 0.0005\n",
    "EPSILON = 0.8\n",
    "A = 3\n",
    "MODEL_PATH = \"./\"\n",
    "MEMORY_PATH = \"./memory\"\n",
    "\n",
    "\n",
    "target_net = DQN()\n",
    "target_net.load_state_dict(torch.load(MODEL_PATH+\"target\", weights_only=True, map_location=torch.device('cpu')))\n",
    "policy_net = DQN()\n",
    "policy_net.load_state_dict(torch.load(MODEL_PATH+\"policy\", weights_only=True, map_location=torch.device('cpu')))\n",
    "\n",
    "\n",
    "\n",
    "memory = Memory(10**5, file=MEMORY_PATH)\n",
    "optimizer = optim.AdamW(policy_net.parameters(), lr=LR, amsgrad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A.L.E: Arcade Learning Environment (version 0.10.1+unknown)\n",
      "[Powered by Stella]\n",
      "/tmp/ipykernel_44335/2248471208.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  next_state_values = torch.tensor(next_state_values)\n"
     ]
    }
   ],
   "source": [
    "play_game(optimizer, memory, policy_net, target_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = \"./\"\n",
    "torch.save(target_net.state_dict(), MODEL_PATH+\"target\")\n",
    "torch.save(policy_net.state_dict(), MODEL_PATH+\"policy\")\n",
    "with open(MEMORY_PATH, 'wb') as f:\n",
    "    pickle.dump(memory.memory, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
